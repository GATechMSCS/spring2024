{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frozenlake import run_gridsearch\n",
    "# from blackjack import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Frozen Lake}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running q_learning with gamma: 0.95 epsilon decay: 0.55  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25000 [00:00<?, ?it/s]/home/leonardo_leads/miniconda3/envs/mlmdp/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "  1%|          | 231/25000 [00:00<00:31, 798.01it/s]/home/leonardo_leads/miniconda3/envs/mlmdp/lib/python3.12/site-packages/bettermdptools/algorithms/rl.py:179: UserWarning: Episode was truncated.  Bootstrapping 0 reward.\n",
      "  warnings.warn(\"Episode was truncated.  Bootstrapping 0 reward.\")\n",
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 20.83 seconds\n",
      "Avg. episode reward:  1.0\n",
      "###################\n",
      "running q_learning with gamma: 0.95 epsilon decay: 0.55  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 44.55 seconds\n",
      "Avg. episode reward:  1.0\n",
      "###################\n",
      "running q_learning with gamma: 0.95 epsilon decay: 0.65  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 23.82 seconds\n",
      "Avg. episode reward:  1.0\n",
      "###################\n",
      "running q_learning with gamma: 0.95 epsilon decay: 0.65  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 45.51 seconds\n",
      "Avg. episode reward:  1.0\n",
      "###################\n",
      "running q_learning with gamma: 0.95 epsilon decay: 0.75  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 22.20 seconds\n",
      "Avg. episode reward:  1.0\n",
      "###################\n",
      "running q_learning with gamma: 0.95 epsilon decay: 0.75  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 47.07 seconds\n",
      "Avg. episode reward:  1.0\n",
      "###################\n",
      "running q_learning with gamma: 0.95 epsilon decay: 1.0  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 22.52 seconds\n",
      "Avg. episode reward:  1.0\n",
      "###################\n",
      "running q_learning with gamma: 0.95 epsilon decay: 1.0  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 43.75 seconds\n",
      "Avg. episode reward:  1.0\n",
      "###################\n",
      "running q_learning with gamma: 1.0 epsilon decay: 0.55  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 57.29 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.0 epsilon decay: 0.55  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 117.37 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.0 epsilon decay: 0.65  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 58.75 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.0 epsilon decay: 0.65  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 115.66 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.0 epsilon decay: 0.75  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 55.93 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.0 epsilon decay: 0.75  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 112.19 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.0 epsilon decay: 1.0  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 52.93 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.0 epsilon decay: 1.0  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 105.49 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.05 epsilon decay: 0.55  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 75.22 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.05 epsilon decay: 0.55  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 20315/50000 [00:51<01:33, 318.68it/s]/home/leonardo_leads/miniconda3/envs/mlmdp/lib/python3.12/site-packages/bettermdptools/algorithms/rl.py:183: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  td_target = reward + gamma * Q[next_state].max() * (not done)\n",
      "/home/leonardo_leads/miniconda3/envs/mlmdp/lib/python3.12/site-packages/bettermdptools/algorithms/rl.py:184: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  td_error = td_target - Q[state][action]\n",
      "/home/leonardo_leads/miniconda3/envs/mlmdp/lib/python3.12/site-packages/bettermdptools/algorithms/rl.py:185: RuntimeWarning: invalid value encountered in scalar add\n",
      "  Q[state][action] = Q[state][action] + alphas[e] * td_error\n",
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 83.78 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.05 epsilon decay: 0.65  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 72.32 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.05 epsilon decay: 0.65  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 82.48 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.05 epsilon decay: 0.75  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 75.21 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.05 epsilon decay: 0.75  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 96.09 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.05 epsilon decay: 1.0  iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 75.51 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n",
      "running q_learning with gamma: 1.05 epsilon decay: 1.0  iterations: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 114.67 seconds\n",
      "Avg. episode reward:  0.0\n",
      "###################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "gamma = [0.95, 1.00, 1.05]\n",
    "epsilon_decay = [0.55, 0.65, 0.75, 1.00]\n",
    "iters = [25000, 50000]\n",
    "size = 8\n",
    "\n",
    "q_learning_results = run_gridsearch(gamma=gamma, epsilon_decay=epsilon_decay, iters=iters, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_learning_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Blackjack}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

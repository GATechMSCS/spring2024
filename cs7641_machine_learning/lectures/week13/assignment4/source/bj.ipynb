{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_env_gs import (make_env, run_ql_search, run_pi_search, run_vi_search)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from gymnasium.spaces import Tuple, Discrete\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "\n",
    "# make environments\n",
    "mdp_bj = 'Blackjack-v1'\n",
    "render_mode_bj = None #'rgb_array'\n",
    "size_bj = Tuple([Discrete(32), Discrete(11), Discrete(2)])\n",
    "ep_steps_bj = 100\n",
    "blackjack = make_env(mdp=mdp_bj,\n",
    "                     size=size_bj,\n",
    "                     slip=None,\n",
    "                     render=render_mode_bj,\n",
    "                     seed=seed,\n",
    "                     prob_frozen=None,\n",
    "                     ep_steps=ep_steps_bj)\n",
    "\n",
    "# BJ\n",
    "# QL\n",
    "iters_ql_bj = 100000\n",
    "gamma_ql_bj = [0.90, 0.99, 0.999]\n",
    "epsilon_decay_ql_bj_edr = [0.90, 0.99, 0.999]\n",
    "init_alpha_ql_bj = [0.30, 0.50, 0.70]\n",
    "\n",
    "# PI\n",
    "iters_pi_bj = 100000\n",
    "gamma_pi_bj = [0.90, 0.99, 0.999]\n",
    "theta_pi_bj = [1e-5, 1e-7, 1e-9]\n",
    "\n",
    "# VI\n",
    "iters_vi_bj = 100000\n",
    "gamma_vi_bj = [0.90, 0.99, 0.999]\n",
    "theta_vi_bj = [1e-5, 1e-7, 1e-9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Blackjack}\\\\~\\\\\n",
    "\\textbf{Q Learning}\\\\\n",
    "\\textbf{Gamma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_learning: gamma=0.9; edr=0.9; ialpha=0.5; episodes=100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo_leads/miniconda3/envs/mlmdp/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime = 13.88 seconds\n",
      "Avg. episode reward:  -0.04967\n",
      "###################\n",
      "\n",
      "q_learning: gamma=0.99; edr=0.9; ialpha=0.5; episodes=100000\n",
      "runtime = 13.92 seconds\n",
      "Avg. episode reward:  -0.0528\n",
      "###################\n",
      "\n",
      "q_learning: gamma=0.999; edr=0.9; ialpha=0.5; episodes=100000\n",
      "runtime = 13.79 seconds\n",
      "Avg. episode reward:  -0.05934\n",
      "###################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([0.9, 0.99, 0.999])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_bj_gamma = run_ql_search(process=blackjack,\n",
    "                        gamma=gamma_ql_bj,\n",
    "                        n_episodes=iters_ql_bj)\n",
    "q_bj_gamma.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Q Learning}\\\\\n",
    "\\textbf{Epsilon Decay Ratio}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_learning: epsilon_decay_ratio=0.9; gamma=0.99; ialpha=0.5; episodes=100000\n",
      "runtime = 13.49 seconds\n",
      "Avg. episode reward:  -0.0528\n",
      "###################\n",
      "\n",
      "q_learning: epsilon_decay_ratio=0.99; gamma=0.99; ialpha=0.5; episodes=100000\n",
      "runtime = 13.44 seconds\n",
      "Avg. episode reward:  -0.04956\n",
      "###################\n",
      "\n",
      "q_learning: epsilon_decay_ratio=0.999; gamma=0.99; ialpha=0.5; episodes=100000\n",
      "runtime = 13.45 seconds\n",
      "Avg. episode reward:  -0.0527\n",
      "###################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([0.9, 0.99, 0.999])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql_bj_edr = run_ql_search(process=blackjack,\n",
    "                        epsilon_decay_ratio=epsilon_decay_ql_bj_edr,\n",
    "                        n_episodes=iters_ql_bj)\n",
    "ql_bj_edr.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Q Learning}\\\\\n",
    "\\textbf{Init Alpha}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_learning: init_alpha=0.3; gamma=0.99; edr=0.9; episodes=100000\n",
      "runtime = 13.39 seconds\n",
      "Avg. episode reward:  -0.0568\n",
      "###################\n",
      "\n",
      "q_learning: init_alpha=0.5; gamma=0.99; edr=0.9; episodes=100000\n",
      "runtime = 13.27 seconds\n",
      "Avg. episode reward:  -0.0528\n",
      "###################\n",
      "\n",
      "q_learning: init_alpha=0.7; gamma=0.99; edr=0.9; episodes=100000\n",
      "runtime = 13.14 seconds\n",
      "Avg. episode reward:  -0.04952\n",
      "###################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([0.3, 0.5, 0.7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql_bj_alpha = run_ql_search(process=blackjack,\n",
    "                        init_alpha=init_alpha_ql_bj,\n",
    "                        n_episodes=iters_ql_bj)\n",
    "ql_bj_alpha.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Policy Iteration}\\\\\n",
    "\\textbf{Gamma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI: gamma=0.9; theta=1e-10; iters=100000\n",
      "runtime = 0.04 seconds\n",
      "Avg. episode reward:  -0.0492\n",
      "###################\n",
      "\n",
      "PI: gamma=0.99; theta=1e-10; iters=100000\n",
      "runtime = 0.04 seconds\n",
      "Avg. episode reward:  -0.04524\n",
      "###################\n",
      "\n",
      "PI: gamma=0.999; theta=1e-10; iters=100000\n",
      "runtime = 0.04 seconds\n",
      "Avg. episode reward:  -0.04524\n",
      "###################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([0.9, 0.99, 0.999])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj_pi_gamma = run_pi_search(process=blackjack,\n",
    "                  gamma=gamma_pi_bj,\n",
    "                  n_iters=iters_pi_bj)\n",
    "bj_pi_gamma.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Policy Iteration}\\\\\n",
    "\\textbf{Theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI: theta=1e-05; gamma=1.0; iters=100000\n",
      "runtime = 0.05 seconds\n",
      "Avg. episode reward:  -0.04524\n",
      "###################\n",
      "\n",
      "PI: theta=1e-07; gamma=1.0; iters=100000\n",
      "runtime = 0.03 seconds\n",
      "Avg. episode reward:  -0.04524\n",
      "###################\n",
      "\n",
      "PI: theta=1e-09; gamma=1.0; iters=100000\n",
      "runtime = 0.04 seconds\n",
      "Avg. episode reward:  -0.04524\n",
      "###################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([1e-05, 1e-07, 1e-09])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj_pi_theta = run_pi_search(process=blackjack,\n",
    "                  theta=theta_pi_bj,\n",
    "                  n_iters=iters_pi_bj)\n",
    "bj_pi_theta.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Value Iteration}\\\\\n",
    "\\textbf{Gamma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VI: gamma=0.9; theta=1e-10; iters=100000\n",
      "runtime = 0.03 seconds\n",
      "Avg. episode reward:  -0.0492\n",
      "###################\n",
      "\n",
      "VI: gamma=0.99; theta=1e-10; iters=100000\n",
      "runtime = 0.02 seconds\n",
      "Avg. episode reward:  -0.04524\n",
      "###################\n",
      "\n",
      "VI: gamma=0.999; theta=1e-10; iters=100000\n",
      "runtime = 0.02 seconds\n",
      "Avg. episode reward:  -0.04524\n",
      "###################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([0.9, 0.99, 0.999])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj_vi_gamma = run_vi_search(process=blackjack,\n",
    "                  gamma=gamma_vi_bj,\n",
    "                  n_iters=iters_vi_bj)\n",
    "bj_vi_gamma.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Value Iteration}\\\\\n",
    "\\textbf{Theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VI: theta=1e-05; gamma=1.0; iters=100000\n",
      "runtime = 0.03 seconds\n",
      "Avg. episode reward:  -0.04524\n",
      "###################\n",
      "\n",
      "VI: theta=1e-07; gamma=1.0; iters=100000\n",
      "runtime = 0.02 seconds\n",
      "Avg. episode reward:  -0.04524\n",
      "###################\n",
      "\n",
      "VI: theta=1e-09; gamma=1.0; iters=100000\n",
      "runtime = 0.02 seconds\n",
      "Avg. episode reward:  -0.04524\n",
      "###################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([1e-05, 1e-07, 1e-09])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj_vi_theta = run_vi_search(process=blackjack,\n",
    "                  theta=theta_vi_bj,\n",
    "                  n_iters=iters_vi_bj)\n",
    "bj_vi_theta.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

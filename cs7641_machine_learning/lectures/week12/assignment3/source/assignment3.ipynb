{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load, preprocess, scale, baseline\n",
    "from wrangle import final_dataset\n",
    "\n",
    "# manipulate data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "from dimensionality_reduction_plots import  (proportion_variance_explained,\n",
    "                                            scree_plot,\n",
    "                                            variance_explained,\n",
    "                                            pca_plot)\n",
    "\n",
    "# put it all together\n",
    "from models import put_it_all_together\n",
    "\n",
    "# Plotting\n",
    "from sklearn.model_selection import (learning_curve, LearningCurveDisplay,\n",
    "                                     validation_curve, ValidationCurveDisplay)\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Cardiovascular Disease}\\\\~\\\\\n",
    "\\textbf{Load, Clean, Preprocess, Scale, Baseline: Cardiovascular Disease}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVD Loading and Cleaning...\n",
      "CVD Loaded and Cleaned...\n",
      "\n",
      "CVD Splitting...\n",
      "CVD Split...\n",
      "\n",
      "CVD Scaling...\n",
      "CVD Scaled...\n",
      "\n",
      "Baseline Accuracy Score: 0.51%\n",
      "\n",
      "CPU times: user 100 ms, sys: 11.6 ms, total: 112 ms\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_scaled_cd, X_test_scaled_cd, y_train_cd, y_test_cd = final_dataset(dataset='cvd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Cardiovascular Disease}\\\\~\\\\\n",
    "\\textbf{Perform All Steps, Run All Models}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running All Steps\n",
      "Step: 1\n",
      "Fitting and Predicting Expectation Maximization\n",
      "Fitting and Predicting Gaussian Mixture\n",
      "Done with Gaussian Mixture\n",
      "Done with Expectation Maximization\n",
      "\n",
      "Fitting and Predicting Clustering\n",
      "Fitting and Predicting KMeans\n",
      "Done with KMeans\n",
      "Done with Clustering\n",
      "Step: 1 Complete\n",
      "\n",
      "Step: 2\n",
      "Fitting PCA\n",
      "Fitting General PCA\n",
      "Done with General PCA\n",
      "Done with PCA\n",
      "\n",
      "Fitting ICA\n",
      "Fitting and Transforming FastICA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo_leads/miniconda3/envs/mluldr/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:582: UserWarning: n_components is too large: it will be set to 5\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with FastICA\n",
      "Done with ICA\n",
      "\n",
      "Fitting and Transforming Randomized Projections\n",
      "Fitting and Transforing with Sparse Random Projection\n",
      "Done with Sparse Random Projection\n",
      "Done with Randomized Projections\n",
      "\n",
      "Fitting and Transforming Manifold Learning\n",
      "Fitting and Transforming with Locally Linear Embedding: Heissan Mapping\n",
      "Done with Locally Linear Embedding: Heissan Mapping\n",
      "Done with Manifold Learning\n",
      "Step: 2 Complete\n",
      "\n",
      "Step: 3\n",
      "Fitting and Predicting Expectation Maximization\n",
      "Fitting and Predicting Gaussian Mixture\n",
      "Done with Gaussian Mixture\n",
      "Done with Expectation Maximization\n",
      "\n",
      "Fitting and Predicting Clustering\n",
      "Fitting and Predicting KMeans\n",
      "Done with KMeans\n",
      "Done with Clustering\n",
      "Fitting and Predicting Expectation Maximization\n",
      "Fitting and Predicting Gaussian Mixture\n",
      "Done with Gaussian Mixture\n",
      "Done with Expectation Maximization\n",
      "\n",
      "Fitting and Predicting Clustering\n",
      "Fitting and Predicting KMeans\n",
      "Done with KMeans\n",
      "Done with Clustering\n",
      "Fitting and Predicting Expectation Maximization\n",
      "Fitting and Predicting Gaussian Mixture\n",
      "Done with Gaussian Mixture\n",
      "Done with Expectation Maximization\n",
      "\n",
      "Fitting and Predicting Clustering\n",
      "Fitting and Predicting KMeans\n",
      "Done with KMeans\n",
      "Done with Clustering\n",
      "Fitting and Predicting Expectation Maximization\n",
      "Fitting and Predicting Gaussian Mixture\n",
      "Done with Gaussian Mixture\n",
      "Done with Expectation Maximization\n",
      "\n",
      "Fitting and Predicting Clustering\n",
      "Fitting and Predicting KMeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo_leads/miniconda3/envs/mluldr/lib/python3.12/site-packages/sklearn/base.py:1351: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with KMeans\n",
      "Done with Clustering\n",
      "Step: 3 Complete\n",
      "\n",
      "Step: 4 (cvd only)\n",
      "\n",
      "Fitting and Predicting PCA NN\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run CVD Model\n",
    "results_cv = put_it_all_together(X_train=X_train_scaled_cd,\n",
    "                                 y_train=y_train_cd,\n",
    "                                 X_test=X_test_scaled_cd,\n",
    "                                 y_test=y_test_cd,\n",
    "                                 dset='cvd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_cv = results_cv['cvd']['step1']\n",
    "step2_cv = results_cv['cvd']['step2']\n",
    "step3_cv = results_cv['cvd']['step3']\n",
    "step4_cv = results_cv['cvd']['step4']\n",
    "step5_cv = results_cv['cvd']['step5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Nutrition Facts}\\\\~\\\\\n",
    "\\textbf{Load, Clean, Preprocess, Scale, Baseline: Nutrition Facts}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_scaled_nf, X_test_scaled_nf, y_train_nf, y_test_nf = final_dataset(dataset='nf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Nutrition Facts}\\\\~\\\\\n",
    "\\textbf{Load, Clean, Preprocess, Scale, Baseline: Nutrition Facts}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run NF Model\n",
    "results_nf = put_it_all_together(X_train=X_train_scaled_nf,\n",
    "                                 y_train=y_train_nf,\n",
    "                                 X_test=X_test_scaled_nf, \n",
    "                                 y_test=y_test_nf,\n",
    "                                 dset='nf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_nf = results_nf['nf']['step1']\n",
    "step2_nf = results_nf['nf']['step2']\n",
    "step3_nf = results_nf['nf']['step3']\n",
    "step4_nf = results_nf['nf']['step4']\n",
    "step5_nf = results_nf['nf']['step5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
